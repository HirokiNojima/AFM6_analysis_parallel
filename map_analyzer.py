import numpy as np
from typing import List, Dict, Any
from afm_data import AFMData
from processing import AFM_Curve_analyzer
from joblib import Parallel, delayed, cpu_count
from data_input import DataReader

# ä¸¦åˆ—å®Ÿè¡Œã®ãŸã‚ã«ã€ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã§ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°ã‚’å®šç¾©
def _analyze_single_curve_wrapper_joblib(
    index_chunk: List[int], 
    folder_path: str,
    metadata_ref: Dict[str, Any]
) -> List[AFMData]:
    """
    ãƒãƒ£ãƒ³ã‚¯å˜ä½ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€åº¦ã ã‘é–‹ãã€èª­ã¿è¾¼ã‚“ã§ã‹ã‚‰è§£æã™ã‚‹ã€‚
    """
    analyzer = AFM_Curve_analyzer()
    reader = DataReader() 
    results_list = []
    
    # 1. ãƒãƒƒãƒèª­ã¿è¾¼ã¿ (ã“ã“ã§TDMSã‚¢ã‚¯ã‚»ã‚¹ã¯1å›ã®ã¿ç™ºç”Ÿ)
    # ----------------------------------------------------
    try:
        # data_objects ã¯ AFMData ã¾ãŸã¯ None ã®ãƒªã‚¹ãƒˆ
        raw_data_objects = reader.read_batch_force_curves(folder_path, index_chunk, metadata_ref)
    except Exception as e:
        print(f"âŒ Batch read failed: {e}")
        # å…¨æ»…ã—ãŸå ´åˆã®ãƒ€ãƒŸãƒ¼å‡¦ç†ãŒå¿…è¦ãªã‚‰ã“ã“ã«è¨˜è¿°
        return []

    # 2. ãƒ¡ãƒ¢ãƒªä¸Šã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’é †æ¬¡è§£æ
    # ----------------------------------------------------
    for i, data_obj in enumerate(raw_data_objects):
        index = index_chunk[i]
        
        if data_obj is None:
            # èª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã®ãƒ€ãƒŸãƒ¼ç”Ÿæˆå‡¦ç† (å…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒæ§˜)
            try:
                xsensor = metadata_ref.get('xsensor', [0.0] * (index + 1))[index]
                ysensor = metadata_ref.get('ysensor', [0.0] * (index + 1))[index]
                data_obj = AFMData(
                    np.array([np.nan]), np.array([np.nan]), np.array([np.nan]),
                    metadata_ref, folder_path, np.array([[np.nan, np.nan]]), 
                    xsensor, ysensor
                )
            except:
                continue # å®Œå…¨ãªå¤±æ•—

        try:
            # è§£æå®Ÿè¡Œ
            analyzer.analyze_single_curve(data_obj)
        except Exception as e:
            print(f"âš ï¸ Index {index} analysis failed: {e}")
            # è§£æå¤±æ•—æ™‚ã‚‚ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆè‡ªä½“ã¯æ®‹ã™ï¼ˆå€¤ã¯NaNï¼‰
        
        # ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ç ´æ£„ã—ã¦ãƒ¡ãƒ¢ãƒªé–‹æ”¾
        data_obj.clear_raw_data()
        results_list.append(data_obj)
        
    return results_list

class AFM_Map_Analyzer_Joblib:
    """
    ãƒ•ã‚©ãƒ¼ã‚¹ãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ï¼ˆAFMDataã®ãƒªã‚¹ãƒˆï¼‰ã‚’joblibã§ä¸¦åˆ—å‡¦ç†ã—è§£æã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    """
    # __init__ã§ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒ
    def __init__(self, n_jobs: int = -1, folder_path: str = "", metadata_ref: Dict[str, Any] = None):
        self.n_jobs = n_jobs
        self.folder_path = folder_path
        self.metadata_ref = metadata_ref
        if not folder_path or metadata_ref is None:
            raise ValueError("folder_pathã¨metadata_refã¯å¿…é ˆã§ã™ã€‚")

    def analyze_map_parallel(self, N_curves: int) -> List[AFMData]:
        """
        ãƒ•ã‚©ãƒ¼ã‚¹ãƒãƒƒãƒ—ã®å…¨ãƒ•ã‚©ãƒ¼ã‚¹ã‚«ãƒ¼ãƒ–ã‚’joblibã§ä¸¦åˆ—å‡¦ç†ã—è§£æã™ã‚‹ã€‚

        Parameters
        ----------
        N_curves : int
            ãƒ•ã‚©ãƒ¼ã‚¹ãƒãƒƒãƒ—å…¨ä½“ã®ã‚«ãƒ¼ãƒ–ç·æ•°ã€‚

        Returns
        -------
        List[AFMData]
            è§£æçµæœãŒæ ¼ç´ã•ã‚ŒãŸAFMDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆã€‚
        """
        
        actual_jobs = cpu_count() if self.n_jobs == -1 else self.n_jobs
        print(f"--- ğŸš€ ãƒ•ã‚©ãƒ¼ã‚¹ãƒãƒƒãƒ—è§£æé–‹å§‹ (joblibä¸¦åˆ—å‡¦ç†, n_jobs={actual_jobs}) ---")

        # 0 ã‹ã‚‰ N_curves-1 ã¾ã§ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ
        all_indices = list(range(N_curves))
        
        # ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
        chunk_size = 50 # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã¯å®Ÿé¨“çš„ã«èª¿æ•´
        data_chunks = [
            all_indices[i:i + chunk_size] 
            for i in range(0, N_curves, chunk_size)
        ]

        # Parallelã¨delayedã‚’ä½¿ç”¨ã—ã¦ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ¯ãƒ¼ã‚«ãƒ¼ã«é…å¸ƒ
        results_list = Parallel(
            n_jobs=self.n_jobs, 
            verbose=1,
            backend='loky'
        )(
            # ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°ã«è¿½åŠ ã®å¼•æ•°ã‚’æ¸¡ã™
            delayed(_analyze_single_curve_wrapper_joblib)(
                chunk, 
                self.folder_path, 
                self.metadata_ref
            ) 
            for chunk in data_chunks
        )
        
        # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã®çµæœã‚’ãƒ•ãƒ©ãƒƒãƒˆãªãƒªã‚¹ãƒˆã«çµåˆ (é †åºã¯ä¿æŒã•ã‚Œã‚‹)
        results_list = [item for sublist in results_list for item in sublist]
        
        print(f"--- âœ… ãƒ•ã‚©ãƒ¼ã‚¹ãƒãƒƒãƒ—è§£æå®Œäº† ---")
        return results_list
    
if __name__ == "__main__":
    # å‹•ä½œç¢ºèªç”¨ã‚³ãƒ¼ãƒ‰
    from afm_data import AFMData
    data = np.loadtxt(r"C:\Users\icell\Desktop\nojima_python\AFM6analysis_20251024\testdata\FCdata.txt")
    z_distance = data[:, 1]
    force = data[:, 0]
    z_sensor = data[:, 2] / 3e+5  # Zã‚»ãƒ³ã‚µãƒ‡ãƒ¼ã‚¿ã‚’é›»åœ§ã«æˆ»ã™ã€‚
    afm_data = AFMData(
        raw_deflection=force,
        raw_ztip=z_distance,
        raw_zsensor=z_sensor,
        metadata_ref={
            'SPRING_CONSTANT': 0.1,  # N/m
            'InvOLS': 1e-9,          # m/V
            'DISTANCE_PER_VOLT': 30e-6 # m/V
        },
        folder_path="C:/test/path",
        hyst_curve = np.loadtxt(r"C:\Users\icell\Desktop\nojima_python\AFM6analysis_20251024\è£œæ­£ç”¨ãƒ‡ãƒ¼ã‚¿\3kHz\mean_FCdata.txt")  # ä»®ã®ãƒ’ã‚¹ãƒ†ãƒªã‚¹æ›²ç·šãƒ‡ãƒ¼ã‚¿
    )
    analyzer = AFM_Map_Analyzer_Joblib(n_jobs=-1)
    results = analyzer.analyze_map_parallel([afm_data for _ in range(100000)])  # åŒã˜ãƒ‡ãƒ¼ã‚¿ã‚’100å€‹è§£æã€‚åŒã˜ãƒ‡ãƒ¼ã‚¿ã®æ™‚ã¯ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã«ã‚ˆã‚Šé«˜é€ŸåŒ–ã•ã‚Œã‚‹ã€‚
    print (results[0].topography)  # æœ€åˆã®ãƒ‡ãƒ¼ã‚¿ã®ãƒˆãƒã‚°ãƒ©ãƒ•ã‚£ãƒ¼é«˜ã•ã‚’è¡¨ç¤º